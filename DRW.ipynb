{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpfuVrFn9gGS",
        "outputId": "bdc31ff3-54bb-4afd-81cc-1ecb02c79590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.4/86.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.4/256.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.3/159.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.0/189.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Token saved. Verifying Kaggle API...\n",
            "Kaggle API 1.8.2\n",
            "ref                                                                              deadline             category          reward  teamCount  userHasEntered  \n",
            "-------------------------------------------------------------------------------  -------------------  ---------  -------------  ---------  --------------  \n",
            "https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3    2026-04-15 23:59:00  Featured   2,207,152 Usd        744           False  \n",
            "https://www.kaggle.com/competitions/passenger-screening-algorithm-challenge      2017-12-15 23:59:00  Featured   1,500,000 Usd        518           False  \n",
            "https://www.kaggle.com/competitions/zillow-prize-1                               2018-01-10 15:59:00  Featured   1,200,000 Usd       3770           False  \n"
          ]
        }
      ],
      "source": [
        "!pip -q install -U kaggle lightgbm pyarrow\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "token = getpass(\"Paste Kaggle Access Token (KGAT_...): \").strip()\n",
        "\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "with open(\"/root/.kaggle/access_token\", \"w\") as f:\n",
        "    f.write(token)\n",
        "os.chmod(\"/root/.kaggle/access_token\", 0o600)\n",
        "\n",
        "os.environ[\"KAGGLE_API_TOKEN\"] = token\n",
        "\n",
        "if os.path.exists(\"/root/.kaggle/kaggle.json\"):\n",
        "    os.rename(\"/root/.kaggle/kaggle.json\", \"/root/.kaggle/kaggle.json.bak\")\n",
        "\n",
        "print(\"✅ Token saved. Verifying Kaggle API...\")\n",
        "!kaggle -v\n",
        "!kaggle competitions list | head -n 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Yg6mia5_JY",
        "outputId": "48037436-4b76-4596-8023-cd9700bd4640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting download (this is large ~6GB). If it disconnects, rerun this cell.\n",
            "\n",
            "=== Attempt 1 ===\n"
          ]
        }
      ],
      "source": [
        "import os, time, subprocess\n",
        "\n",
        "COMP = \"drw-crypto-market-prediction\"\n",
        "OUT_DIR = \"/content/drw_data\"\n",
        "ZIP_PATH = f\"{OUT_DIR}/{COMP}.zip\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def file_size_mb(path):\n",
        "    return os.path.getsize(path) / (1024**2) if os.path.exists(path) else 0\n",
        "\n",
        "print(\"Starting download (this is large ~6GB). If it disconnects, rerun this cell.\")\n",
        "\n",
        "# 反复调用 download（Kaggle 会自动 resume），直到 zip 通过 unzip -t 检查\n",
        "for attempt in range(1, 50):\n",
        "    print(f\"\\n=== Attempt {attempt} ===\")\n",
        "    # 运行下载（失败也继续尝试）\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"kaggle\", \"competitions\", \"download\", \"-c\", COMP, \"-p\", OUT_DIR],\n",
        "            check=False\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"Download call error:\", e)\n",
        "\n",
        "    sz = file_size_mb(ZIP_PATH)\n",
        "    print(f\"Current zip size: {sz:.1f} MB\")\n",
        "\n",
        "    # 如果文件存在就尝试检查完整性（只有下载完才会通过）\n",
        "    if os.path.exists(ZIP_PATH) and sz > 100:  # 有点大小再测\n",
        "        test = subprocess.run([\"unzip\", \"-t\", ZIP_PATH], capture_output=True, text=True)\n",
        "        if test.returncode == 0:\n",
        "            print(\" Zip integrity OK (unzip -t passed).\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Zip not complete yet (unzip -t failed). Continue downloading...\")\n",
        "    time.sleep(10)\n",
        "\n",
        "print(\"\\nDone. Zip path:\", ZIP_PATH, \"size(MB):\", file_size_mb(ZIP_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmj3Vdke6j6E",
        "outputId": "c638580e-4c40-42af-c39a-ba51bd699e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 13G\n",
            "-rw-r--r-- 1 root root 6.0G Jul  9 23:28 drw-crypto-market-prediction.zip\n",
            "-rw-r--r-- 1 root root  14M Jul  9 23:18 sample_submission.csv\n",
            "-rw-r--r-- 1 root root 3.2G Jul  9 23:18 test.parquet\n",
            "-rw-r--r-- 1 root root 3.1G Jul  9 23:22 train.parquet\n"
          ]
        }
      ],
      "source": [
        "!unzip -q /content/drw_data/drw-crypto-market-prediction.zip -d /content/drw_data\n",
        "!ls -lh /content/drw_data | head -n 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7nBftPDZ3ktS",
        "outputId": "b6ad2471-c10f-492e-b39d-4348af4f1188"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drw_data/train.parquet'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3597523056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mLABEL_COL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATA_DIR}/train.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATA_DIR}/test.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msub\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATA_DIR}/sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drw_data/train.parquet'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "DATA_DIR = \"/content/drw_data\"\n",
        "SEEDS = [42, 202, 3407]\n",
        "LABEL_COL = \"label\"\n",
        "\n",
        "train = pd.read_parquet(f\"{DATA_DIR}/train.parquet\")\n",
        "test  = pd.read_parquet(f\"{DATA_DIR}/test.parquet\")\n",
        "sub   = pd.read_csv(f\"{DATA_DIR}/sample_submission.csv\")\n",
        "\n",
        "pred_col = sub.columns[1]\n",
        "print(\"train:\", train.shape, \"test:\", test.shape, \"sub:\", sub.shape)\n",
        "print(\"submission columns:\", sub.columns.tolist())\n",
        "\n",
        "def add_row_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    eps = 1e-12\n",
        "    df[\"ba_imbalance\"] = (df[\"bid_qty\"] - df[\"ask_qty\"]) / (df[\"bid_qty\"] + df[\"ask_qty\"] + eps)\n",
        "    df[\"trade_imbalance\"] = (df[\"buy_qty\"] - df[\"sell_qty\"]) / (df[\"buy_qty\"] + df[\"sell_qty\"] + eps)\n",
        "    df[\"volume_over_depth\"] = df[\"volume\"] / (df[\"bid_qty\"] + df[\"ask_qty\"] + eps)\n",
        "    df[\"buy_ratio\"]  = df[\"buy_qty\"]  / (df[\"volume\"] + eps)\n",
        "    df[\"sell_ratio\"] = df[\"sell_qty\"] / (df[\"volume\"] + eps)\n",
        "    df[\"vol_over_trades\"] = df[\"volume\"] / (df[\"buy_qty\"] + df[\"sell_qty\"] + eps)\n",
        "\n",
        "    for c in [\"volume_over_depth\", \"vol_over_trades\", \"buy_ratio\", \"sell_ratio\"]:\n",
        "        lo, hi = df[c].quantile(0.01), df[c].quantile(0.99)\n",
        "        df[c] = df[c].clip(lo, hi)\n",
        "    return df\n",
        "\n",
        "def zscore(a):\n",
        "    a = np.asarray(a)\n",
        "    return (a - a.mean()) / (a.std() + 1e-12)\n",
        "\n",
        "train_fe = add_row_features(train)\n",
        "test_fe  = add_row_features(test)\n",
        "\n",
        "feature_cols = [c for c in train_fe.columns if c not in [LABEL_COL, \"timestamp\"]]\n",
        "X = train_fe[feature_cols]\n",
        "y = train_fe[LABEL_COL]\n",
        "X_test = test_fe[feature_cols]\n",
        "\n",
        "imp = SimpleImputer(strategy=\"median\")\n",
        "X_imp = imp.fit_transform(X)\n",
        "X_test_imp = imp.transform(X_test)\n",
        "\n",
        "preds = []\n",
        "for sd in SEEDS:\n",
        "    m = LGBMRegressor(\n",
        "        n_estimators=3500,\n",
        "        learning_rate=0.02,\n",
        "        num_leaves=64,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=sd,\n",
        "    )\n",
        "    m.fit(X_imp, y)\n",
        "    preds.append(zscore(m.predict(X_test_imp)))\n",
        "\n",
        "pred_ens = zscore(np.mean(preds, axis=0))\n",
        "\n",
        "sub_out = sub.copy()\n",
        "sub_out[pred_col] = pred_ens\n",
        "out_path = \"/content/submission_ensemble.csv\"\n",
        "sub_out.to_csv(out_path, index=False)\n",
        "\n",
        "print(\"Saved:\", out_path)\n",
        "sub_out.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
